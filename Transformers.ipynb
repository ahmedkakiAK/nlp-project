{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88a47e81",
   "metadata": {},
   "source": [
    "# Premier entraînement sur les données Kaggle (binaire)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
=======
   "execution_count": 1,
>>>>>>> 985fe9229cc21452a483c30a2ae2b551a5b9b0cc
   "id": "d0168127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 18,
=======
   "execution_count": 2,
>>>>>>> 985fe9229cc21452a483c30a2ae2b551a5b9b0cc
   "id": "369f87d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 20000  # Taille du vocabulaire max\n",
    "MAX_LEN = 256           # Longueur max des séquences\n",
    "EMBED_DIM = 100         # Dimension des embeddings\n",
    "HIDDEN_DIM = 128        # Taille des couches LSTM\n",
    "BATCH_SIZE = 16         # Taille des batchs\n",
    "EPOCHS = 10              # Nombre d'époques"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
=======
   "execution_count": 3,
>>>>>>> 985fe9229cc21452a483c30a2ae2b551a5b9b0cc
   "id": "14e4b6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_df_kaggle = pd.read_csv(\"data/kaggle/preprocessed/train.csv\")\n",
    "test_df_kaggle = pd.read_csv(\"data/kaggle/preprocessed/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
=======
   "execution_count": 4,
>>>>>>> 985fe9229cc21452a483c30a2ae2b551a5b9b0cc
   "id": "231d399c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return text.split()\n",
    "\n",
    "def encode(vocab, text):\n",
    "    return [vocab.get(tok, 1) for tok in tokenize(text)[:MAX_LEN]]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
=======
   "execution_count": 6,
>>>>>>> 985fe9229cc21452a483c30a2ae2b551a5b9b0cc
   "id": "e761020b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary\n",
    "counter_kaggle = Counter()\n",
    "for text in train_df_kaggle[\"text\"]:\n",
    "    tokens_kaggle = tokenize(text)\n",
    "    counter_kaggle.update(tokens_kaggle)\n",
    "\n",
    "most_common_kaggle = counter_kaggle.most_common(MAX_VOCAB_SIZE - 2)\n",
    "vocab_kaggle = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "for i, (word, _) in enumerate(most_common_kaggle, start=2):\n",
    "    vocab_kaggle[word] = i"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 22,
=======
   "execution_count": 7,
>>>>>>> 985fe9229cc21452a483c30a2ae2b551a5b9b0cc
   "id": "adb1b58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, df, vocab, max_len=512):\n",
    "        self.texts = [torch.tensor(encode(vocab, text), dtype=torch.long) for text in df[\"text\"]]\n",
    "        self.labels = torch.tensor(df[\"label\"].values, dtype=torch.long)\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Create attention mask\n",
    "        attention_mask = torch.ones_like(text)  # 1 for real tokens, 0 for padding\n",
    "        \n",
    "        # Ensure the text is of max_len\n",
    "        if len(text) > self.max_len:\n",
    "            text = text[:self.max_len]\n",
    "            attention_mask = attention_mask[:self.max_len]\n",
    "        else:\n",
    "            # Padding\n",
    "            padding_length = self.max_len - len(text)\n",
    "            text = torch.cat([text, torch.zeros(padding_length, dtype=torch.long)], dim=0)\n",
    "            attention_mask = torch.cat([attention_mask, torch.zeros(padding_length, dtype=torch.long)], dim=0)\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": text,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": label\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 23,
=======
   "execution_count": 8,
>>>>>>> 985fe9229cc21452a483c30a2ae2b551a5b9b0cc
   "id": "e8cfbbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # Sort batch by length for packing\n",
    "    texts = [item[\"input_ids\"] for item in batch]\n",
    "    labels = [item[\"labels\"] for item in batch]\n",
    "    attention_masks = [item[\"attention_mask\"] for item in batch]\n",
    "    \n",
    "    # Pad sequences\n",
    "    texts = pad_sequence(texts, batch_first=True, padding_value=0)\n",
    "    attention_masks = pad_sequence(attention_masks, batch_first=True, padding_value=0)\n",
    "    \n",
    "    # Convert labels to tensor\n",
    "    labels = torch.tensor(labels)\n",
    "    \n",
    "    # Return a dictionary\n",
    "    return {\n",
    "        \"input_ids\": texts,\n",
    "        \"attention_mask\": attention_masks,\n",
    "        \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 24,
=======
   "execution_count": 9,
>>>>>>> 985fe9229cc21452a483c30a2ae2b551a5b9b0cc
   "id": "b6e3eabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaders\n",
    "train_ds_kaggle = TextDataset(train_df_kaggle, vocab_kaggle)\n",
    "test_ds_kaggle = TextDataset(test_df_kaggle, vocab_kaggle)\n",
    "\n",
    "train_loader_kaggle = DataLoader(train_ds_kaggle, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader_kaggle = DataLoader(test_ds_kaggle, batch_size=32, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 25,
=======
   "execution_count": 10,
>>>>>>> 985fe9229cc21452a483c30a2ae2b551a5b9b0cc
   "id": "7dad6ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads, hidden_dim, num_layers, output_dim, max_len=512, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.positional_encoding = self._generate_positional_encoding(max_len, embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dim_feedforward=hidden_dim, dropout=dropout, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.fc = nn.Linear(embed_dim, output_dim)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        x = self.embedding(input_ids) + self.positional_encoding[:input_ids.size(1)].unsqueeze(0).to(input_ids.device)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        if attention_mask is not None:\n",
    "            # Transformer expects 0 for attend, -inf for mask; convert accordingly\n",
    "            mask = (attention_mask == 0).to(torch.bool)\n",
    "        else:\n",
    "            mask = None\n",
    "\n",
    "        x = self.transformer_encoder(x, src_key_padding_mask=mask)\n",
    "        cls_output = x[:, 0, :]  # Use first token ([CLS]-like)\n",
    "        return self.fc(cls_output)\n",
    "\n",
    "    def _generate_positional_encoding(self, max_len, d_model):\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        return pe\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 26,
=======
   "execution_count": 11,
>>>>>>> 985fe9229cc21452a483c30a2ae2b551a5b9b0cc
   "id": "759bcfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Using device: cuda\n"
=======
      "Using device: cpu\n"
>>>>>>> 985fe9229cc21452a483c30a2ae2b551a5b9b0cc
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "# Initialize model"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 27,
=======
   "execution_count": 12,
>>>>>>> 985fe9229cc21452a483c30a2ae2b551a5b9b0cc
   "id": "080405ba",
   "metadata": {},
   "outputs": [
    {
<<<<<<< HEAD
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss_Total: 89.1185; Mean_Loss: 0.5605\n",
      "Epoch 2 Loss_Total: 50.9657; Mean_Loss: 0.3205\n",
      "Epoch 3 Loss_Total: 32.5799; Mean_Loss: 0.2049\n",
      "Epoch 4 Loss_Total: 24.9433; Mean_Loss: 0.1569\n",
      "Epoch 5 Loss_Total: 20.4756; Mean_Loss: 0.1288\n",
      "Epoch 6 Loss_Total: 11.4577; Mean_Loss: 0.0721\n",
      "Epoch 7 Loss_Total: 8.4406; Mean_Loss: 0.0531\n",
      "Epoch 8 Loss_Total: 7.0760; Mean_Loss: 0.0445\n",
      "Epoch 9 Loss_Total: 6.4271; Mean_Loss: 0.0404\n",
      "Epoch 10 Loss_Total: 5.0477; Mean_Loss: 0.0317\n",
      "Epoch 11 Loss_Total: 4.5896; Mean_Loss: 0.0289\n",
      "Epoch 12 Loss_Total: 3.1302; Mean_Loss: 0.0197\n",
      "Epoch 13 Loss_Total: 3.5439; Mean_Loss: 0.0223\n",
      "Epoch 14 Loss_Total: 3.8629; Mean_Loss: 0.0243\n",
      "Epoch 15 Loss_Total: 2.5371; Mean_Loss: 0.0160\n",
      "Epoch 16 Loss_Total: 2.1772; Mean_Loss: 0.0137\n",
      "Epoch 17 Loss_Total: 1.3928; Mean_Loss: 0.0088\n",
      "Epoch 18 Loss_Total: 3.1255; Mean_Loss: 0.0197\n",
      "Epoch 19 Loss_Total: 2.3271; Mean_Loss: 0.0146\n",
      "Epoch 20 Loss_Total: 1.3623; Mean_Loss: 0.0086\n"
=======
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     25\u001b[0m optimizer_kaggle\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 26\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_kaggle\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     28\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 23\u001b[0m, in \u001b[0;36mTransformerClassifier.forward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     21\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m cls_output \u001b[38;5;241m=\u001b[39m x[:, \u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# Use first token ([CLS]-like)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(cls_output)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/transformer.py:391\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    388\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 391\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    394\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.\u001b[39m, src\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/transformer.py:714\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    712\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 714\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    715\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/transformer.py:722\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sa_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor,\n\u001b[1;32m    721\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 722\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    726\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/activation.py:1241\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1227\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1228\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1229\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1239\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1241\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/functional.py:5476\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5473\u001b[0m k \u001b[38;5;241m=\u001b[39m k\u001b[38;5;241m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[1;32m   5474\u001b[0m v \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[0;32m-> 5476\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5477\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(bsz \u001b[38;5;241m*\u001b[39m tgt_len, embed_dim)\n\u001b[1;32m   5479\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m linear(attn_output, out_proj_weight, out_proj_bias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
>>>>>>> 985fe9229cc21452a483c30a2ae2b551a5b9b0cc
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model_kaggle = TransformerClassifier(\n",
    "    vocab_size=MAX_VOCAB_SIZE,\n",
    "    embed_dim=EMBED_DIM, \n",
    "    hidden_dim=HIDDEN_DIM, \n",
    "    num_heads=2,\n",
    "    num_layers=2,\n",
    "    output_dim=len(train_df_kaggle[\"label\"].unique())\n",
    ")\n",
    "model_kaggle = model_kaggle.to(device)\n",
    "\n",
    "# Optimizer / Loss\n",
    "optimizer_kaggle = torch.optim.AdamW(model_kaggle.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training\n",
    "for epoch in range(20):\n",
    "    model_kaggle.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader_kaggle:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer_kaggle.zero_grad()\n",
    "        outputs = model_kaggle(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_kaggle.step()\n",
    "        total_loss += loss.item()\n",
    "        mean_loss = total_loss/len(train_loader_kaggle)\n",
    "    print(f\"Epoch {epoch+1} Loss_Total: {total_loss:.4f}; Mean_Loss: {mean_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c50b9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/torch/nn/modules/transformer.py:505: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
      "  output = torch._nested_tensor_from_mask(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       624\n",
      "           1       0.95      0.90      0.92       643\n",
      "\n",
      "    accuracy                           0.92      1267\n",
      "   macro avg       0.92      0.92      0.92      1267\n",
      "weighted avg       0.92      0.92      0.92      1267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_kaggle.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader_kaggle:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels']\n",
    "        outputs = model_kaggle(input_ids, attention_mask)\n",
    "        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "print(classification_report(all_labels, all_preds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b690de8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6612d30a",
   "metadata": {},
   "source": [
    "# Deuxième entraînement sur les données ISOT (binaire)\n",
    "C'est exactement la même chose. On donne un autre nom au modèle pour pouvoir les conserver et les évaluer plus tard pour la généralisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2fec8cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_df_isot = pd.read_csv(\"data/isot/preprocessed/train.csv\")\n",
    "test_df_isot = pd.read_csv(\"data/isot/preprocessed/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff99a27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary\n",
    "counter_isot = Counter()\n",
    "for text in train_df_isot[\"text\"]:\n",
    "    tokens_isot = tokenize(text)\n",
    "    counter_isot.update(tokens_isot)\n",
    "\n",
    "most_common_isot = counter_isot.most_common(MAX_VOCAB_SIZE - 2)\n",
    "vocab_isot = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "for i, (word, _) in enumerate(most_common_isot, start=2):\n",
    "    vocab_isot[word] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da0994e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaders\n",
    "train_ds_isot = TextDataset(train_df_isot, vocab_isot)\n",
    "test_ds_isot = TextDataset(test_df_isot, vocab_isot)\n",
    "\n",
    "train_loader_isot = DataLoader(train_ds_isot, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader_isot = DataLoader(test_ds_isot, batch_size=32, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb05acfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss_Total: 143.2250; Mean_Loss: 0.1275\n",
      "Epoch 2 Loss_Total: 44.7731; Mean_Loss: 0.0399\n",
      "Epoch 3 Loss_Total: 25.4382; Mean_Loss: 0.0227\n",
      "Epoch 4 Loss_Total: 19.1650; Mean_Loss: 0.0171\n",
      "Epoch 5 Loss_Total: 16.1931; Mean_Loss: 0.0144\n",
      "Epoch 6 Loss_Total: 12.0888; Mean_Loss: 0.0108\n",
      "Epoch 7 Loss_Total: 11.7849; Mean_Loss: 0.0105\n",
      "Epoch 8 Loss_Total: 10.0826; Mean_Loss: 0.0090\n",
      "Epoch 9 Loss_Total: 9.0866; Mean_Loss: 0.0081\n",
      "Epoch 10 Loss_Total: 7.4877; Mean_Loss: 0.0067\n",
      "Epoch 11 Loss_Total: 7.0403; Mean_Loss: 0.0063\n",
      "Epoch 12 Loss_Total: 7.1872; Mean_Loss: 0.0064\n",
      "Epoch 13 Loss_Total: 5.0366; Mean_Loss: 0.0045\n",
      "Epoch 14 Loss_Total: 4.5546; Mean_Loss: 0.0041\n",
      "Epoch 15 Loss_Total: 4.7874; Mean_Loss: 0.0043\n",
      "Epoch 16 Loss_Total: 3.6353; Mean_Loss: 0.0032\n",
      "Epoch 17 Loss_Total: 4.0017; Mean_Loss: 0.0036\n",
      "Epoch 18 Loss_Total: 3.5775; Mean_Loss: 0.0032\n",
      "Epoch 19 Loss_Total: 3.2757; Mean_Loss: 0.0029\n",
      "Epoch 20 Loss_Total: 3.9475; Mean_Loss: 0.0035\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model_isot = TransformerClassifier(\n",
    "    vocab_size=MAX_VOCAB_SIZE,\n",
    "    embed_dim=EMBED_DIM, \n",
    "    hidden_dim=HIDDEN_DIM, \n",
    "    num_heads=2,\n",
    "    num_layers=2,\n",
    "    output_dim=len(train_df_isot[\"label\"].unique())\n",
    ")\n",
    "model_isot = model_isot.to(device)\n",
    "\n",
    "# Optimizer / Loss\n",
    "optimizer_isot = torch.optim.AdamW(model_isot.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training\n",
    "for epoch in range(20):\n",
    "    model_isot.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader_isot:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer_isot.zero_grad()\n",
    "        outputs = model_isot(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_isot.step()\n",
    "        total_loss += loss.item()\n",
    "        mean_loss = total_loss/len(train_loader_isot)\n",
    "    print(f\"Epoch {epoch+1} Loss_Total: {total_loss:.4f}; Mean_Loss: {mean_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3a75107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4702\n",
      "           1       1.00      0.99      0.99      4278\n",
      "\n",
      "    accuracy                           0.99      8980\n",
      "   macro avg       0.99      0.99      0.99      8980\n",
      "weighted avg       0.99      0.99      0.99      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_isot.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader_isot:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels']\n",
    "        outputs = model_isot(input_ids, attention_mask)\n",
    "        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "print(classification_report(all_labels, all_preds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f7a68d",
   "metadata": {},
   "source": [
    "# Généralisation : Entrainement sur Kaggle et évaluation sur ISOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69b25909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.53      0.52      4702\n",
      "           1       0.47      0.46      0.46      4278\n",
      "\n",
      "    accuracy                           0.49      8980\n",
      "   macro avg       0.49      0.49      0.49      8980\n",
      "weighted avg       0.49      0.49      0.49      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_kaggle.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader_isot:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels']\n",
    "        outputs = model_kaggle(input_ids, attention_mask)\n",
    "        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "print(classification_report(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8d551a",
   "metadata": {},
   "source": [
    "# Généralisation : Entrainement sur ISOT et évaluation sur Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e6fba1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.81      0.60       624\n",
      "           1       0.42      0.14      0.20       643\n",
      "\n",
      "    accuracy                           0.47      1267\n",
      "   macro avg       0.45      0.47      0.40      1267\n",
      "weighted avg       0.45      0.47      0.40      1267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_isot.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader_kaggle:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels']\n",
    "        outputs = model_isot(input_ids, attention_mask)\n",
    "        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "print(classification_report(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3878783",
   "metadata": {},
   "source": [
    "## Modèle avec probabilité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82c1273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerClassifier_proba(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads, hidden_dim, num_layers, output_dim, max_len=512, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.positional_encoding = self._generate_positional_encoding(max_len, embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dim_feedforward=hidden_dim, dropout=dropout, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.fc = nn.Linear(embed_dim, output_dim)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        x = self.embedding(input_ids) + self.positional_encoding[:input_ids.size(1)].unsqueeze(0).to(input_ids.device)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        if attention_mask is not None:\n",
    "            # Transformer expects 0 for attend, -inf for mask; convert accordingly\n",
    "            mask = (attention_mask == 0).to(torch.bool)\n",
    "        else:\n",
    "            mask = None\n",
    "\n",
    "        x = self.transformer_encoder(x, src_key_padding_mask=mask)\n",
    "        cls_output = x[:, 0, :]  # Use first token ([CLS]-like)\n",
    "        return torch.sigmoid(self.fc(cls_output))  # proba entre 0 et 1\n",
    "\n",
    "    def _generate_positional_encoding(self, max_len, d_model):\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        return pe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae842e4",
   "metadata": {},
   "source": [
    "### kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7b18e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss_Total: 106.5038; Mean_Loss: 0.6698\n",
      "Epoch 2 Loss_Total: 101.8930; Mean_Loss: 0.6408\n",
      "Epoch 3 Loss_Total: 98.8413; Mean_Loss: 0.6216\n",
      "Epoch 4 Loss_Total: 94.3353; Mean_Loss: 0.5933\n",
      "Epoch 5 Loss_Total: 92.4582; Mean_Loss: 0.5815\n",
      "Epoch 6 Loss_Total: 89.2288; Mean_Loss: 0.5612\n",
      "Epoch 7 Loss_Total: 91.0380; Mean_Loss: 0.5726\n",
      "Epoch 8 Loss_Total: 88.8916; Mean_Loss: 0.5591\n",
      "Epoch 9 Loss_Total: 89.3191; Mean_Loss: 0.5618\n",
      "Epoch 10 Loss_Total: 87.4721; Mean_Loss: 0.5501\n",
      "Epoch 11 Loss_Total: 86.5830; Mean_Loss: 0.5445\n",
      "Epoch 12 Loss_Total: 85.9203; Mean_Loss: 0.5404\n",
      "Epoch 13 Loss_Total: 84.9456; Mean_Loss: 0.5342\n",
      "Epoch 14 Loss_Total: 86.3445; Mean_Loss: 0.5430\n",
      "Epoch 15 Loss_Total: 84.8910; Mean_Loss: 0.5339\n",
      "Epoch 16 Loss_Total: 84.3436; Mean_Loss: 0.5305\n",
      "Epoch 17 Loss_Total: 84.5882; Mean_Loss: 0.5320\n",
      "Epoch 18 Loss_Total: 84.5304; Mean_Loss: 0.5316\n",
      "Epoch 19 Loss_Total: 84.0642; Mean_Loss: 0.5287\n",
      "Epoch 20 Loss_Total: 84.2995; Mean_Loss: 0.5302\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model_kaggle_proba = TransformerClassifier_proba(\n",
    "    vocab_size=MAX_VOCAB_SIZE,\n",
    "    embed_dim=EMBED_DIM, \n",
    "    hidden_dim=HIDDEN_DIM, \n",
    "    num_heads=2,\n",
    "    num_layers=2,\n",
    "    output_dim = 1\n",
    ")\n",
    "model_kaggle_proba = model_kaggle_proba.to(device)\n",
    "\n",
    "# Optimizer / Loss\n",
    "optimizer_kaggle_proba = torch.optim.AdamW(model_kaggle_proba.parameters(), lr=1e-3)\n",
    "criterion = nn.BCEWithLogitsLoss()  # pas CrossEntropyLoss\n",
    "\n",
    "# Training\n",
    "for epoch in range(20):\n",
    "    model_kaggle_proba.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader_kaggle:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].float().unsqueeze(1).to(device)  # reshape pour [batch_size, 1]\n",
    "\n",
    "        optimizer_kaggle_proba.zero_grad()\n",
    "        outputs = model_kaggle_proba(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_kaggle_proba.step()\n",
    "        total_loss += loss.item()\n",
    "        mean_loss = total_loss/len(train_loader_kaggle)\n",
    "    print(f\"Epoch {epoch+1} Loss_Total: {total_loss:.4f}; Mean_Loss: {mean_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "095fcea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.90      0.90       624\n",
      "         1.0       0.91      0.90      0.90       643\n",
      "\n",
      "    accuracy                           0.90      1267\n",
      "   macro avg       0.90      0.90      0.90      1267\n",
      "weighted avg       0.90      0.90      0.90      1267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model_kaggle_proba.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader_kaggle:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].float().unsqueeze(1).to(device)  # [batch_size, 1]\n",
    "\n",
    "        outputs = model_kaggle_proba(input_ids, attention_mask)  # proba ∈ [0,1]\n",
    "        preds = (outputs > 0.5).int().cpu().numpy()  # seuil à 0.5\n",
    "        all_preds.extend(preds.flatten())\n",
    "        all_labels.extend(labels.cpu().numpy().flatten())\n",
    "\n",
    "print(classification_report(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13b5272",
   "metadata": {},
   "source": [
    "### ISOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db774dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_isot_proba = TransformerClassifier_proba(\n",
    "    vocab_size=MAX_VOCAB_SIZE,\n",
    "    embed_dim=EMBED_DIM, \n",
    "    hidden_dim=HIDDEN_DIM, \n",
    "    num_heads=2,\n",
    "    num_layers=2,\n",
    "    output_dim = 1\n",
    ")\n",
    "model_isot_proba = model_isot_proba.to(device)\n",
    "\n",
    "# Optimizer / Loss\n",
    "optimizer_isot_proba = torch.optim.AdamW(model_isot_proba.parameters(), lr=1e-3)\n",
    "criterion = nn.BCEWithLogitsLoss()  # pas CrossEntropyLoss\n",
    "\n",
    "# Training\n",
    "for epoch in range(20):\n",
    "    model_isot_proba.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader_isot:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].float().unsqueeze(1).to(device)  # reshape pour [batch_size, 1]\n",
    "\n",
    "        optimizer_isot_proba.zero_grad()\n",
    "        outputs = model_isot_proba(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_isot_proba.step()\n",
    "        total_loss += loss.item()\n",
    "        mean_loss = total_loss/len(train_loader_isot)\n",
    "    print(f\"Epoch {epoch+1} Loss_Total: {total_loss:.4f}; Mean_Loss: {mean_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96a7000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model_isot_proba.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader_isot:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].float().unsqueeze(1).to(device)  # [batch_size, 1]\n",
    "\n",
    "        outputs = model_isot_proba(input_ids, attention_mask)  # proba ∈ [0,1]\n",
    "        preds = (outputs > 0.5).int().cpu().numpy()  # seuil à 0.5\n",
    "        all_preds.extend(preds.flatten())\n",
    "        all_labels.extend(labels.cpu().numpy().flatten())\n",
    "\n",
    "print(classification_report(all_labels, all_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
